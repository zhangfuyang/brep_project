data_params:
  class_type: LatentDataset # LatentDataset_temp
  train_data_pkl_path: 'reconstruction/logs/latent_dim_4_train/lightning_logs/version_0/pkl'
  val_data_pkl_path: 'reconstruction/logs/latent_dim_4_val/lightning_logs/version_0/pkl'
  train_batch_size: 128
  val_batch_size: 20
  num_workers: 32
  max_faces: 20
  face_shuffle: True
  debug: False
  debug_size: 10
  fake_latent_path: 'reconstruction/logs/fake_dim_4.npy'
  pad_fake_latent: False

model_params:
  in_channels: 4
  out_channels: 4
  solid_params:
    encode_params:
      types: ["EncodeDownBlock3D", "EncodeDownBlock3D", "EncodeDownBlock3D", "EncodeBlock3D"]
      attns: [False, False, False, True]
    mid_params:
      types: ["EncodeBlock3D"]
      attns: [True]
    decode_params:
      types: ["DecodeBlock3D", "DecodeUpBlock3D", "DecodeUpBlock3D", "DecodeUpBlock3D"]
      attns: [True, False, False, False]
  face_params:
    encode_params:
      types: ["EncodeDownBlock3D", "EncodeDownBlock3D", "EncodeDownBlock3D", "EncodeBlock3D"]
      attns: [False, False, False, True]
    mid_params:
      types: ["EncodeBlock3D"]
      attns: [False]
    decode_params:
      types: ["DecodeBlock3D", "DecodeUpBlock3D", "DecodeUpBlock3D", "DecodeUpBlock3D"]
      attns: [True, False, False, False]
  cross_attn_params:
    zero_init: False
    encoding_num: 0 # number of position encoding
    f2f_model: [False, False, False, True,  True,  True, False, False, False]
    f2s_model: [False, False, False, True,   True,  True, False, False, False]
    s2f_model: [False, False, False, True,   True,   True, False, False, False]
    f2f_downscale: [0, 0, 0, 0,   0,    0, 0, 0, 0]
    f2s_downscale: [0, 0, 0, 0,   0,    0, 0, 0, 0]
    s2f_downscale: [0, 0, 0, 0,   0,    0, 0, 0, 0]
    conv_out: False
  #block_channels: [32, 64, 128, 128, 128, 128, 64, 32, 32]
  #block_channels: [64, 128, 256, 256, 256, 256, 128, 64, 64]
  block_channels: [64, 128, 256, 512, 512, 256, 128, 64, 64]
  layers_per_block: 2
  attention_head_dim: 8
  norm_num_groups: 32
  norm_eps: 1.e-5
  freq_shift: 0
  flip_sin_to_cos: True
  act_fn: 'silu'
  has_solid_model: True

trainer_params:
  manual_seed: 123
  accelerator: 'gpu'
  max_epochs: 5000
  precision: 32
  num_nodes: 1
  devices: 3
  strategy: 'ddp'
  log_every_n_steps: 100
  limit_val_batches: 1
  val_check_interval: 2000
  num_sanity_val_steps: 1
  detect_anomaly: False
  accumulate_grad_batches: 1
  gradient_clip_val: 1.0
  default_root_dir: 'sdf_diffusion/logs/latent_full_generate_face_solid_f2s'

exp_params:
  render_type: 'face_solid'
  prediction_type: 'sample' # epsilon or sample
  lr: 0.00005
  weight_decay: 0.0
  lr_decay: 0.999
  loss_type: "l2" # l1 or l2
  diffusion_steps: 50
  face_model:
    config: 'vqvae/logs/vqvae_face_dist_codebook_dim_4/lightning_logs/version_1/config.yaml'
    pretrained_path: 'vqvae/logs/vqvae_face_dist_codebook_dim_4/lightning_logs/version_1/checkpoints/last-model-epoch=76.ckpt'
  sdf_model: 
    config: 'vqvae/logs/vqvae_voxel_sdf_codebook_dim_4/lightning_logs/version_1/config.yaml'
    pretrained_path: 'vqvae/logs/vqvae_voxel_sdf_codebook_dim_4/lightning_logs/version_1/checkpoints/last-model-epoch=76.ckpt'
  latent_std_mean_path: 'reconstruction/logs/latent_dim_4_mean_std.pkl'
  face_diffusion_model:
    pretrained_path: null #'diffusion_transformer/logs/face_only/lightning_logs/version_0/checkpoints/last-model-epoch=59.ckpt'
  pretrained_model_path: null #'sdf_diffusion/logs/latent_full_generate_face_solid/lightning_logs/version_0/checkpoints/last-model-epoch=888.ckpt'
  generate_solid: True
